{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from textblob import Word\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import random\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read File, Select Desired Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (25,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'inspection, dielectric. leak at digger(fitting in cab) ,remove extension shaft from winch,emg. stop not working at controls, boom cuts out(wait or play with outriggers works)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=pd.read_csv('Data1.csv', encoding='ISO-8859-1', error_bad_lines=False).loc[:, [\"SR Summary\"]][\"SR Summary\"];\n",
    "file[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inspection dielectric leak at digger fitting in cab remove extension shaft from winch emg stop not working at controls boom cuts out wait or play with outriggers works'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean=[re.sub(r\"  +\",\" \",re.sub(r\"(?![\\w\\s]).\", \" \",line).lower()).strip() for line in file] #remove non-alphaneumeric\n",
    "clean=list(filter(lambda x: x!='road service request' and x!='service request', clean))\n",
    "clean_grams=[re.sub(r\"  +\",\" \",re.sub(r\"( (and|or|not) )((and|or|not) )*\",\" \",line)).strip() for line in clean] #remove connection words\n",
    "clean[1] # 49010 48831 48981 48802 re.sub(r\" (and|or|not) \",\" \", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tokens, Bigrams, Trigrams, 4-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "appended_summary=\" \".join([line for line in clean])\n",
    "tokens = nltk.word_tokenize(appended_summary)\n",
    "freq = nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boom', 7516),\n",
       " ('inspection', 6413),\n",
       " ('pm', 6216),\n",
       " ('and', 5924),\n",
       " ('unit', 5312),\n",
       " ('leak', 4484),\n",
       " ('dielectric', 4020),\n",
       " ('not', 3835),\n",
       " ('in', 3612),\n",
       " ('at', 3495)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('pm', 'inspection'), 3098),\n",
       " (('dielectric', 'test'), 2664),\n",
       " (('leak', 'at'), 2054),\n",
       " (('inspection', 'dielectric'), 1508),\n",
       " (('pm', 'dielectric'), 1488),\n",
       " (('hydraulic', 'leak'), 1441),\n",
       " (('stuck', 'in'), 1221),\n",
       " (('unit', 'down'), 1067),\n",
       " (('boom', 'functions'), 1058),\n",
       " (('repairs', 'from'), 967)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = [bigram for line in clean_grams for bigram in list(nltk.bigrams(line.split(\" \")))]\n",
    "bigram_freq = nltk.FreqDist(list(bigrams))\n",
    "sorted_bigram_freq = bigram_freq.most_common()\n",
    "sorted_bigram_freq[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trigrams = [trigram for line in clean_grams for trigram in list(nltk.trigrams(line.split(\" \")))]\n",
    "trigram_freq = nltk.FreqDist(list(trigrams))\n",
    "sorted_trigram_freq = trigram_freq.most_common()\n",
    "sorted_trigram_freq[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fourgrams = [fourgram for line in clean_grams for fourgram in list(nltk.ngrams(line.split(\" \"), 4))]\n",
    "fourgram_freq = nltk.FreqDist(list(fourgrams))\n",
    "sorted_fourgram_freq = fourgram_freq.most_common()\n",
    "sorted_fourgram_freq[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def verb_checker(pair):\n",
    "    if pair[1].startswith(\"V\"):\n",
    "        \n",
    "        return Word(pair[0]).lemmatize(\"v\")\n",
    "    else:\n",
    "        return pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  Searched in:\n    - 'C:\\\\Users\\\\elahe/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\elahe\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-73c93a010602>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mverb_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtagged\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \"\"\"\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'file:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger')\n  \u001b[0m\n  Searched in:\n    - 'C:\\\\Users\\\\elahe/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\elahe\\\\AppData\\\\Roaming\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "new_tokens = [verb_checker(item) for item in tagged] \n",
    "new_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens_tagged = nltk.pos_tag(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_of_pos = {\"VB\":[], \"JJ\":[], \"RB\":[], \"NN\":[]}\n",
    "for token in set(new_tokens):\n",
    "    pair = nltk.pos_tag([token])[0]\n",
    "    if pair[1].startswith(\"VB\"):\n",
    "        dic_of_pos[\"VB\"].append(pair[0])\n",
    "    if pair[1].startswith(\"JJ\"):\n",
    "        dic_of_pos[\"JJ\"].append(pair[0])\n",
    "    if pair[1].startswith(\"NN\"):\n",
    "        dic_of_pos[\"NN\"].append(pair[0])\n",
    "    if pair[1].startswith(\"RB\"):\n",
    "        dic_of_pos[\"RB\"].append(pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boom', 7553),\n",
       " ('inspection', 6413),\n",
       " ('pm', 6216),\n",
       " ('leak', 5938),\n",
       " ('and', 5924),\n",
       " ('unit', 5312),\n",
       " ('dielectric', 4020),\n",
       " ('not', 3835),\n",
       " ('in', 3612),\n",
       " ('at', 3495)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens_freq = nltk.FreqDist(new_tokens)\n",
    "new_tokens_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Nouns/Verbs/Adjectives/Adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boom', 7516),\n",
       " ('inspection', 6413),\n",
       " ('pm', 6216),\n",
       " ('unit', 5312),\n",
       " ('leak', 4484),\n",
       " ('dielectric', 4020),\n",
       " ('test', 2929),\n",
       " ('pole', 2821),\n",
       " ('auger', 2765),\n",
       " ('winch', 2749),\n",
       " ('ucr', 2449),\n",
       " ('hydraulic', 2369),\n",
       " ('functions', 2166),\n",
       " ('rotation', 1819),\n",
       " ('controls', 1800),\n",
       " ('repairs', 1779),\n",
       " ('inop', 1564),\n",
       " ('stuck', 1356),\n",
       " ('check', 1338),\n",
       " ('digger', 1326),\n",
       " ('dot', 1297),\n",
       " ('throttle', 1289),\n",
       " ('perform', 1253),\n",
       " ('stage', 1238),\n",
       " ('hose', 1194),\n",
       " ('issues', 1186),\n",
       " ('air', 1141),\n",
       " ('broken', 1141),\n",
       " ('repair', 1113),\n",
       " ('outrigger', 1089),\n",
       " ('csn', 1081),\n",
       " ('hyd', 996),\n",
       " ('guide', 990),\n",
       " ('oil', 984),\n",
       " ('install', 968),\n",
       " ('control', 961),\n",
       " ('pto', 882),\n",
       " ('t', 873),\n",
       " ('derrick', 845),\n",
       " ('intermittent', 839),\n",
       " ('hop', 809),\n",
       " ('stow', 784),\n",
       " ('level', 780),\n",
       " ('function', 736),\n",
       " ('b', 714),\n",
       " ('cylinder', 700),\n",
       " ('won', 678),\n",
       " ('valve', 669),\n",
       " ('switch', 652),\n",
       " ('pin', 622),\n",
       " ('front', 615),\n",
       " ('remote', 607),\n",
       " ('issue', 600),\n",
       " ('needs', 594),\n",
       " ('gearbox', 585),\n",
       " ('tool', 533),\n",
       " ('line', 531),\n",
       " ('tip', 529),\n",
       " ('service', 511),\n",
       " ('blown', 494),\n",
       " ('pedestal', 492),\n",
       " ('chassis', 487),\n",
       " ('radio', 483),\n",
       " ('extend', 464),\n",
       " ('reel', 461),\n",
       " ('motor', 458),\n",
       " ('guides', 451),\n",
       " ('pump', 451),\n",
       " ('claws', 448),\n",
       " ('bracket', 427),\n",
       " ('side', 421),\n",
       " ('wash', 416),\n",
       " ('outriggers', 414),\n",
       " ('truck', 407),\n",
       " ('work', 395),\n",
       " ('hoses', 390),\n",
       " ('rope', 387),\n",
       " ('speed', 372),\n",
       " ('rear', 365),\n",
       " ('power', 362),\n",
       " ('operation', 360),\n",
       " ('bent', 357),\n",
       " ('customer', 352),\n",
       " ('month', 349),\n",
       " ('turret', 346),\n",
       " ('pressure', 344),\n",
       " ('return', 339),\n",
       " ('stop', 329),\n",
       " ('stops', 325),\n",
       " ('gear', 325),\n",
       " ('load', 322),\n",
       " ('need', 316),\n",
       " ('tube', 315),\n",
       " ('joint', 313),\n",
       " ('rotary', 305),\n",
       " ('bolts', 304),\n",
       " ('claw', 301),\n",
       " ('box', 299),\n",
       " ('light', 297),\n",
       " ('interlock', 291)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = dic_of_pos[\"NN\"]\n",
    "noun_freq = [(item, freq[item]) for item in nouns]\n",
    "sorted_noun_freq = sorted(noun_freq, key = lambda x: x[1], reverse = True)\n",
    "sorted_noun_freq[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('replace', 2466),\n",
       " ('be', 2270),\n",
       " ('slow', 935),\n",
       " ('have', 631),\n",
       " ('go', 594),\n",
       " ('come', 401),\n",
       " ('do', 307),\n",
       " ('make', 261),\n",
       " ('get', 241),\n",
       " ('lose', 195),\n",
       " ('remove', 194),\n",
       " ('run', 191),\n",
       " ('add', 162),\n",
       " ('leaking', 155),\n",
       " ('leave', 100),\n",
       " ('sling', 91),\n",
       " ('keep', 91),\n",
       " ('fell', 71),\n",
       " ('see', 56),\n",
       " ('swing', 54),\n",
       " ('take', 41),\n",
       " ('let', 32),\n",
       " ('cracked', 22),\n",
       " ('apply', 20),\n",
       " ('find', 17),\n",
       " ('losing', 15),\n",
       " ('multifunctioning', 14),\n",
       " ('energize', 14),\n",
       " ('popping', 12),\n",
       " ('making', 11),\n",
       " ('believe', 10),\n",
       " ('oring', 10),\n",
       " ('digging', 10),\n",
       " ('extended', 10),\n",
       " ('loosing', 10),\n",
       " ('follow', 10),\n",
       " ('lost', 9),\n",
       " ('approve', 9),\n",
       " ('damaged', 8),\n",
       " ('busted', 8),\n",
       " ('approved', 8),\n",
       " ('say', 8),\n",
       " ('appear', 7),\n",
       " ('replaced', 7),\n",
       " ('allow', 7),\n",
       " ('sticking', 7),\n",
       " ('grinding', 7),\n",
       " ('working', 7),\n",
       " ('attached', 6),\n",
       " ('rehose', 6),\n",
       " ('cavitating', 5),\n",
       " ('retractted', 5),\n",
       " ('needed', 5),\n",
       " ('feathering', 5),\n",
       " ('give', 5),\n",
       " ('enclose', 5),\n",
       " ('engaged', 4),\n",
       " ('lifting', 4),\n",
       " ('phased', 4),\n",
       " ('cutting', 4),\n",
       " ('following', 4),\n",
       " ('drifting', 4),\n",
       " ('mounting', 4),\n",
       " ('kicking', 3),\n",
       " ('installed', 3),\n",
       " ('buy', 3),\n",
       " ('testing', 3),\n",
       " ('engauged', 3),\n",
       " ('cooling', 3),\n",
       " ('save', 3),\n",
       " ('lekaing', 3),\n",
       " ('malfunctioning', 3),\n",
       " ('failed', 3),\n",
       " ('activated', 3),\n",
       " ('recalibrated', 3),\n",
       " ('happen', 3),\n",
       " ('energized', 3),\n",
       " ('missing', 3),\n",
       " ('stowed', 3),\n",
       " ('required', 3),\n",
       " ('lighting', 3),\n",
       " ('malfuntioning', 2),\n",
       " ('warning', 2),\n",
       " ('twisted', 2),\n",
       " ('operting', 2),\n",
       " ('retracting', 2),\n",
       " ('causing', 2),\n",
       " ('rotating', 2),\n",
       " ('reprogrammed', 2),\n",
       " ('fixed', 2),\n",
       " ('grounding', 2),\n",
       " ('wing', 2),\n",
       " ('riding', 2),\n",
       " ('updated', 2),\n",
       " ('used', 2),\n",
       " ('loaded', 2),\n",
       " ('tagged', 2),\n",
       " ('roading', 2),\n",
       " ('hissing', 2),\n",
       " ('engergized', 2)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = dic_of_pos[\"VB\"]\n",
    "verb_freq = [(item, new_tokens_freq[item]) for item in verbs]\n",
    "sorted_verb_freq = sorted(verb_freq, key = lambda x: x[1], reverse = True)\n",
    "sorted_verb_freq[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inoperable', 1294),\n",
       " ('annual', 1261),\n",
       " ('upper', 1233),\n",
       " ('lower', 631),\n",
       " ('new', 338),\n",
       " ('loose', 269),\n",
       " ('turntable', 264),\n",
       " ('high', 259),\n",
       " ('third', 253),\n",
       " ('bad', 242)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = dic_of_pos[\"JJ\"]\n",
    "adj_freq = [(item, freq[item]) for item in adj ]\n",
    "sorted_adj_freq= sorted(adj_freq, key = lambda x:x[1], reverse = True)\n",
    "sorted_adj_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 3835),\n",
       " ('down', 2043),\n",
       " ('up', 1020),\n",
       " ('intermittently', 280),\n",
       " ('only', 244),\n",
       " ('back', 190),\n",
       " ('properly', 146),\n",
       " ('too', 124),\n",
       " ('very', 122),\n",
       " ('correctly', 117)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adverbs = dic_of_pos[\"RB\"]\n",
    "adverb_freq = [(item, freq[item]) for item in adverbs]\n",
    "sorted_adverb_freq = sorted(adverb_freq, key = lambda x: x[1], reverse = True)\n",
    "sorted_adverb_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rotary', 'won t', 'broken', 'boom functions', 'upper controls']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_str(vec):\n",
    "    if isinstance(vec, tuple):\n",
    "        return \" \".join(vec).strip()\n",
    "    return vec.strip()\n",
    "\n",
    "def feature_provider(parameter_vector):\n",
    "    feature_pool=[sorted_noun_freq, sorted_verb_freq, sorted_adj_freq, sorted_adverb_freq, sorted_bigram_freq]\n",
    "    features=[]\n",
    "    for i in range(len(parameter_vector)):\n",
    "        features+=[get_str(feature[0]) for feature in feature_pool[i][0:parameter_vector[i]]]\n",
    "    return list(set(features))\n",
    "\n",
    "features_used = feature_provider([100,0,0,0,20])\n",
    "np.savetxt(\"features.csv\", np.array(features_used), delimiter=\",\", fmt=\"%s\")\n",
    "features_used[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary=[]\n",
    "for index in range(0, len(clean)):\n",
    "    binary += ([[int(feature in clean[index]) for feature in features_used[:-100]] + [int(feature in clean_grams[0]) for feature in features_used[-100:]]])\n",
    "binary[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=16, random_state=0)\n",
    "kmeans = kmeans.fit(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  2, 14,  2,  9,  8,  8, 15,  3,  0, 15, 15, 15, 15, 15,  2,  6,\n",
       "       13,  3, 15])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complete foot pedal wiring',\n",
       " 'inspection dielectric leak at digger fitting in cab remove extension shaft from winch emg stop not working at controls boom cuts out wait or play with outriggers works',\n",
       " 'annual pm dielectric and dot inspection',\n",
       " 'hose ripped at upper controls',\n",
       " 'change hyd oil to hvi 13 change hyd filter pole claws will not go down',\n",
       " 'changeout winch out rope hyd tank sight glass leak engine won t ramp up when pto turned on',\n",
       " 'check rear throttle oil leak',\n",
       " 'annual inspection',\n",
       " 'annual pm inspection dielectric test',\n",
       " 's i upper boom wear',\n",
       " 'digger shift',\n",
       " 'repair impact',\n",
       " 'replace throttle',\n",
       " 'see list jr877',\n",
       " 'see list jr876',\n",
       " 'rear control cover streetside tray cover tall cone holder',\n",
       " 'aecon service call to cambridge',\n",
       " 'road service',\n",
       " 'annual inspection ndt test dielectric test',\n",
       " 'annual inspection ndt test']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rotary', 'won t', 'broken', 'boom functions', 'upper controls',\n",
       "       'functions', 'load', 'dielectric test', 'leak', 'unit', 'leak in',\n",
       "       'repairs', 'extend', 'air', 'claws', 'valve', 'level b',\n",
       "       'customer', 'leak at', 'annual pm', 'line', 'in the', 'pole',\n",
       "       'chassis', 'stow', 'bracket', 'tube', 'throttle', 'interlock',\n",
       "       'issue', 'needs', 'repairs from', 'side', 'pump', 'truck',\n",
       "       'switch', 'dielectric', 'outrigger', 'guide', 'stops', 'stuck',\n",
       "       'remote', 'power', 'hop', 'from inspection', 'csn',\n",
       "       'pm dielectric', 'tool', 'controls', 'pressure', 'blown', 'radio',\n",
       "       'bolts', 'ucr', 'perform', 'b derrick', 'intermittent',\n",
       "       'hydraulic leak', 'motor', 'boom', 'level', 'box', 'pole guide',\n",
       "       'bent', 'outriggers', 'inspection dielectric', 'digger', 'rear',\n",
       "       'light', 'won', 'gear', 'install', 'repair', 'tip', 'unit down',\n",
       "       'front', 'inop', 'return', 'auger', 'gearbox', 'control', 'rope',\n",
       "       'hoses', 'service', 'check', 'dot', 'test', 'pedestal', 'issues',\n",
       "       'work', 'hyd', 'cylinder', 't', 'claw', 'pin', 'boom stuck', 'b',\n",
       "       'month', 'inspection', 'derrick', 'speed', 'stop', 'hydraulic',\n",
       "       'winch', 'stage', 'pm inspection', 'pto', 'stuck in', 'need',\n",
       "       'wash', 'turret', 'oil', 'hose', 'reel', 'operation', 'guides',\n",
       "       'joint', 'function', 'pm', 'rotation'], dtype='<U21')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
