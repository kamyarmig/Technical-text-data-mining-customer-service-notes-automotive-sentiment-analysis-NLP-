{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from textblob import Word\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import random\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read File, Select Desired Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/Desktop/SDCard/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (25,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-- CUT OFF AND REPLACED DAMAGED AREA OF REAR BUMPER - INSTALLED NEW HINGES - PAINTED AREA\\n-- STRAIGHTENED TOW EYES\\n-- REPLACED AUGER BRACKET ROLL PIN\\n-- REPLACED AND ADJUSTED TRANSFER PIN \\n-- REPAIRED BOOM GEL COTE\\n-- REPAIRED HOSE CARRIER TUBE; - COMPLETED ANNUAL PM INPECTION\\n- COMPLETED DIELECTRIC TEST\\n- REMOVED AND REPLACED HOSE REEL\\n- REMOVED HOSE CLAMP TIES TO CHECK HOSES UNDER CHASSIS FOR DAMAGE - ADDED HOSE PROTECTION\\n- CLEANED TRANSFER TUBES - TIGHTENED FITTINGS\\n- REINSTALLED TWO SPEED FITTING AT DIGGER \\n- REPLACED POLE GUIDE BUSHINGS AND SHIMS\\n- ADJUSTED TRANSFER BRACKET\\n- TIGHTENED FITTING AT DIGGER MOTOR\\n- ADJUSTED POLE GUIDE INTERLOCK\\n- TIGHTENED FITTING AT TURRET\\n- TOPPED UP HYDRAULIC OIL\\n- REPLACED GASKET AT RETURN ON HYDRAULIC TANK\\n- REPLACED MALE TOOL COUPLERS AT HOSE REEL\\n- REPLACED DAMAGED AND MISSING DUST CAPS ON TOOL COUPLERS\\n- REMOVED CAPSTAN EXTENSION - WAS SEIZED - HAD TO CUT OFF - CLEANED UP SHAFT - REPLACED EXTENSION\\n- COMPLETED OPERATION TEST\\n- CHECKED OPERATION OF BOOM - CUTS OUT SOMETIMES - NO FAULT FOUND\\n- INSPECTED AND CLEANED EMERGENCY STOP'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=pd.read_csv('Data3.csv', encoding='ISO-8859-1', error_bad_lines=False).loc[:, [\"SR_NOTE_CORRECTION\"]][\"SR_NOTE_CORRECTION\"];\n",
    "file[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cut off and replaced damaged area of rear bumper installed new hinges painted area straightened tow eyes replaced auger bracket roll pin replaced and adjusted transfer pin repaired boom gel cote repaired hose carrier tube completed annual pm inpection completed dielectric test removed and replaced hose reel removed hose clamp ties to check hoses under chassis for damage added hose protection cleaned transfer tubes tightened fittings reinstalled two speed fitting at digger replaced pole guide bushings and shims adjusted transfer bracket tightened fitting at digger motor adjusted pole guide interlock tightened fitting at turret topped up hydraulic oil replaced gasket at return on hydraulic tank replaced male tool couplers at hose reel replaced damaged and missing dust caps on tool couplers removed capstan extension was seized had to cut off cleaned up shaft replaced extension completed operation test checked operation of boom cuts out sometimes no fault found inspected and cleaned emergency stop'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean=[re.sub(r\"  +\",\" \",re.sub(r\"((?![\\w\\s]).|\\n)\", \" \",line).lower()).strip() for line in file] #remove non-alphaneumeric\n",
    "# clean=list(filter(lambda x: x!='road service request' and x!='service request', clean))\n",
    "clean_grams=[re.sub(r\"  +\",\" \",re.sub(r\"( (and|or|not) )((and|or|not) )*\",\" \",line)).strip() for line in clean] #remove connection words\n",
    "clean[1] # 49010 48831 48981 48802 re.sub(r\" (and|or|not) \",\" \", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tokens, Bigrams, Trigrams, 4-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "appended_summary=\" \".join([line for line in clean_grams])\n",
    "tokens = nltk.word_tokenize(appended_summary)\n",
    "freq = nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 194566),\n",
       " ('unit', 134989),\n",
       " ('the', 132311),\n",
       " ('from', 68426),\n",
       " ('on', 54740),\n",
       " ('for', 46371),\n",
       " ('boom', 45889),\n",
       " ('at', 43880),\n",
       " ('found', 40540),\n",
       " ('in', 40132)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('unit', 'to'), 18043),\n",
       " (('traveled', 'from'), 15511),\n",
       " (('to', 'service'), 14850),\n",
       " (('travel', 'from'), 13771),\n",
       " (('set', 'up'), 13393),\n",
       " (('the', 'unit'), 13375),\n",
       " (('pole', 'guide'), 11342),\n",
       " (('up', 'unit'), 10772),\n",
       " (('installed', 'new'), 9189),\n",
       " (('traveled', 'to'), 9154)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = [bigram for line in clean_grams for bigram in list(nltk.bigrams(line.split(\" \")))]\n",
    "bigram_freq = nltk.FreqDist(list(bigrams))\n",
    "sorted_bigram_freq = bigram_freq.most_common()\n",
    "sorted_bigram_freq[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = [trigram for line in clean_grams for trigram in list(nltk.trigrams(line.split(\" \")))]\n",
    "trigram_freq = nltk.FreqDist(list(trigrams))\n",
    "sorted_trigram_freq = trigram_freq.most_common()\n",
    "sorted_trigram_freq[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourgrams = [fourgram for line in clean_grams for fourgram in list(nltk.ngrams(line.split(\" \"), 4))]\n",
    "fourgram_freq = nltk.FreqDist(list(fourgrams))\n",
    "sorted_fourgram_freq = fourgram_freq.most_common()\n",
    "sorted_fourgram_freq[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def verb_checker(pair):\n",
    "    if pair[1].startswith(\"V\"):\n",
    "        \n",
    "        return Word(pair[0]).lemmatize(\"v\")\n",
    "    else:\n",
    "        return pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 'cut', 'off', 'replace', 'damage']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "new_tokens = [verb_checker(item) for item in tagged] \n",
    "new_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens_tagged = nltk.pos_tag(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_of_pos = {\"VB\":[], \"JJ\":[], \"RB\":[], \"NN\":[]}\n",
    "for token in set(new_tokens):\n",
    "    pair = nltk.pos_tag([token])[0]\n",
    "    if pair[1].startswith(\"VB\"):\n",
    "        dic_of_pos[\"VB\"].append(pair[0])\n",
    "    if pair[1].startswith(\"JJ\"):\n",
    "        dic_of_pos[\"JJ\"].append(pair[0])\n",
    "    if pair[1].startswith(\"NN\"):\n",
    "        dic_of_pos[\"NN\"].append(pair[0])\n",
    "    if pair[1].startswith(\"RB\"):\n",
    "        dic_of_pos[\"RB\"].append(pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boom', 7553),\n",
       " ('inspection', 6413),\n",
       " ('pm', 6216),\n",
       " ('leak', 5938),\n",
       " ('and', 5924),\n",
       " ('unit', 5312),\n",
       " ('dielectric', 4020),\n",
       " ('not', 3835),\n",
       " ('in', 3612),\n",
       " ('at', 3495)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens_freq = nltk.FreqDist(new_tokens)\n",
    "new_tokens_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Nouns/Verbs/Adjectives/Adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boom', 7516),\n",
       " ('inspection', 6413),\n",
       " ('pm', 6216),\n",
       " ('unit', 5312),\n",
       " ('leak', 4484),\n",
       " ('dielectric', 4020),\n",
       " ('test', 2929),\n",
       " ('pole', 2821),\n",
       " ('auger', 2765),\n",
       " ('winch', 2749),\n",
       " ('ucr', 2449),\n",
       " ('hydraulic', 2369),\n",
       " ('functions', 2166),\n",
       " ('rotation', 1819),\n",
       " ('controls', 1800),\n",
       " ('repairs', 1779),\n",
       " ('inop', 1564),\n",
       " ('stuck', 1356),\n",
       " ('check', 1338),\n",
       " ('digger', 1326),\n",
       " ('dot', 1297),\n",
       " ('throttle', 1289),\n",
       " ('perform', 1253),\n",
       " ('stage', 1238),\n",
       " ('hose', 1194),\n",
       " ('issues', 1186),\n",
       " ('air', 1141),\n",
       " ('broken', 1141),\n",
       " ('repair', 1113),\n",
       " ('outrigger', 1089),\n",
       " ('csn', 1081),\n",
       " ('hyd', 996),\n",
       " ('guide', 990),\n",
       " ('oil', 984),\n",
       " ('install', 968),\n",
       " ('control', 961),\n",
       " ('pto', 882),\n",
       " ('t', 873),\n",
       " ('derrick', 845),\n",
       " ('intermittent', 839),\n",
       " ('hop', 809),\n",
       " ('stow', 784),\n",
       " ('level', 780),\n",
       " ('function', 736),\n",
       " ('b', 714),\n",
       " ('cylinder', 700),\n",
       " ('won', 678),\n",
       " ('valve', 669),\n",
       " ('switch', 652),\n",
       " ('pin', 622),\n",
       " ('front', 615),\n",
       " ('remote', 607),\n",
       " ('issue', 600),\n",
       " ('needs', 594),\n",
       " ('gearbox', 585),\n",
       " ('tool', 533),\n",
       " ('line', 531),\n",
       " ('tip', 529),\n",
       " ('service', 511),\n",
       " ('blown', 494),\n",
       " ('pedestal', 492),\n",
       " ('chassis', 487),\n",
       " ('radio', 483),\n",
       " ('extend', 464),\n",
       " ('reel', 461),\n",
       " ('motor', 458),\n",
       " ('guides', 451),\n",
       " ('pump', 451),\n",
       " ('claws', 448),\n",
       " ('bracket', 427),\n",
       " ('side', 421),\n",
       " ('wash', 416),\n",
       " ('outriggers', 414),\n",
       " ('truck', 407),\n",
       " ('work', 395),\n",
       " ('hoses', 390),\n",
       " ('rope', 387),\n",
       " ('speed', 372),\n",
       " ('rear', 365),\n",
       " ('power', 362),\n",
       " ('operation', 360),\n",
       " ('bent', 357),\n",
       " ('customer', 352),\n",
       " ('month', 349),\n",
       " ('turret', 346),\n",
       " ('pressure', 344),\n",
       " ('return', 339),\n",
       " ('stop', 329),\n",
       " ('stops', 325),\n",
       " ('gear', 325),\n",
       " ('load', 322),\n",
       " ('need', 316),\n",
       " ('tube', 315),\n",
       " ('joint', 313),\n",
       " ('rotary', 305),\n",
       " ('bolts', 304),\n",
       " ('claw', 301),\n",
       " ('box', 299),\n",
       " ('light', 297),\n",
       " ('interlock', 291)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = dic_of_pos[\"NN\"]\n",
    "noun_freq = [(item, freq[item]) for item in nouns]\n",
    "sorted_noun_freq = sorted(noun_freq, key = lambda x: x[1], reverse = True)\n",
    "sorted_noun_freq[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('replace', 2466),\n",
       " ('be', 2270),\n",
       " ('slow', 935),\n",
       " ('have', 631),\n",
       " ('go', 594),\n",
       " ('come', 401),\n",
       " ('do', 307),\n",
       " ('make', 261),\n",
       " ('get', 241),\n",
       " ('lose', 195),\n",
       " ('remove', 194),\n",
       " ('run', 191),\n",
       " ('add', 162),\n",
       " ('leaking', 155),\n",
       " ('leave', 100),\n",
       " ('sling', 91),\n",
       " ('keep', 91),\n",
       " ('fell', 71),\n",
       " ('see', 56),\n",
       " ('swing', 54),\n",
       " ('take', 41),\n",
       " ('let', 32),\n",
       " ('cracked', 22),\n",
       " ('apply', 20),\n",
       " ('find', 17),\n",
       " ('losing', 15),\n",
       " ('multifunctioning', 14),\n",
       " ('energize', 14),\n",
       " ('popping', 12),\n",
       " ('making', 11),\n",
       " ('believe', 10),\n",
       " ('oring', 10),\n",
       " ('digging', 10),\n",
       " ('extended', 10),\n",
       " ('loosing', 10),\n",
       " ('follow', 10),\n",
       " ('lost', 9),\n",
       " ('approve', 9),\n",
       " ('damaged', 8),\n",
       " ('busted', 8),\n",
       " ('approved', 8),\n",
       " ('say', 8),\n",
       " ('appear', 7),\n",
       " ('replaced', 7),\n",
       " ('allow', 7),\n",
       " ('sticking', 7),\n",
       " ('grinding', 7),\n",
       " ('working', 7),\n",
       " ('attached', 6),\n",
       " ('rehose', 6),\n",
       " ('cavitating', 5),\n",
       " ('retractted', 5),\n",
       " ('needed', 5),\n",
       " ('feathering', 5),\n",
       " ('give', 5),\n",
       " ('enclose', 5),\n",
       " ('engaged', 4),\n",
       " ('lifting', 4),\n",
       " ('phased', 4),\n",
       " ('cutting', 4),\n",
       " ('following', 4),\n",
       " ('drifting', 4),\n",
       " ('mounting', 4),\n",
       " ('kicking', 3),\n",
       " ('installed', 3),\n",
       " ('buy', 3),\n",
       " ('testing', 3),\n",
       " ('engauged', 3),\n",
       " ('cooling', 3),\n",
       " ('save', 3),\n",
       " ('lekaing', 3),\n",
       " ('malfunctioning', 3),\n",
       " ('failed', 3),\n",
       " ('activated', 3),\n",
       " ('recalibrated', 3),\n",
       " ('happen', 3),\n",
       " ('energized', 3),\n",
       " ('missing', 3),\n",
       " ('stowed', 3),\n",
       " ('required', 3),\n",
       " ('lighting', 3),\n",
       " ('malfuntioning', 2),\n",
       " ('warning', 2),\n",
       " ('twisted', 2),\n",
       " ('operting', 2),\n",
       " ('retracting', 2),\n",
       " ('causing', 2),\n",
       " ('rotating', 2),\n",
       " ('reprogrammed', 2),\n",
       " ('fixed', 2),\n",
       " ('grounding', 2),\n",
       " ('wing', 2),\n",
       " ('riding', 2),\n",
       " ('updated', 2),\n",
       " ('used', 2),\n",
       " ('loaded', 2),\n",
       " ('tagged', 2),\n",
       " ('roading', 2),\n",
       " ('hissing', 2),\n",
       " ('engergized', 2)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = dic_of_pos[\"VB\"]\n",
    "verb_freq = [(item, new_tokens_freq[item]) for item in verbs]\n",
    "sorted_verb_freq = sorted(verb_freq, key = lambda x: x[1], reverse = True)\n",
    "sorted_verb_freq[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inoperable', 1294),\n",
       " ('annual', 1261),\n",
       " ('upper', 1233),\n",
       " ('lower', 631),\n",
       " ('new', 338),\n",
       " ('loose', 269),\n",
       " ('turntable', 264),\n",
       " ('high', 259),\n",
       " ('third', 253),\n",
       " ('bad', 242)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = dic_of_pos[\"JJ\"]\n",
    "adj_freq = [(item, freq[item]) for item in adj ]\n",
    "sorted_adj_freq= sorted(adj_freq, key = lambda x:x[1], reverse = True)\n",
    "sorted_adj_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 3835),\n",
       " ('down', 2043),\n",
       " ('up', 1020),\n",
       " ('intermittently', 280),\n",
       " ('only', 244),\n",
       " ('back', 190),\n",
       " ('properly', 146),\n",
       " ('too', 124),\n",
       " ('very', 122),\n",
       " ('correctly', 117)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adverbs = dic_of_pos[\"RB\"]\n",
    "adverb_freq = [(item, freq[item]) for item in adverbs]\n",
    "sorted_adverb_freq = sorted(adverb_freq, key = lambda x: x[1], reverse = True)\n",
    "sorted_adverb_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rotary', 'won t', 'broken', 'boom functions', 'upper controls']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_str(vec):\n",
    "    if isinstance(vec, tuple):\n",
    "        return \" \".join(vec).strip()\n",
    "    return vec.strip()\n",
    "\n",
    "def feature_provider(parameter_vector):\n",
    "    feature_pool=[sorted_noun_freq, sorted_verb_freq, sorted_adj_freq, sorted_adverb_freq, sorted_bigram_freq]\n",
    "    features=[]\n",
    "    for i in range(len(parameter_vector)):\n",
    "        features+=[get_str(feature[0]) for feature in feature_pool[i][0:parameter_vector[i]]]\n",
    "    return list(set(features))\n",
    "\n",
    "features_used = feature_provider([1000,0,0,0,20])\n",
    "np.savetxt(\"features2.csv\", np.array(features_used), delimiter=\",\", fmt=\"%s\")\n",
    "features_used[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary=[]\n",
    "for index in range(0, len(clean)):\n",
    "    binary += ([[int(feature in clean[index]) for feature in features_used[:-100]] + [int(feature in clean_grams[0]) for feature in features_used[-100:]]])\n",
    "binary[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
