{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "from textblob import Word\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import random\n",
    "import pandas as pd\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read File, Select Desired Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inspection, dielectric. leak at digger(fitting in cab) ,remove extension shaft from winch,emg. stop not working at controls, boom cuts out(wait or play with outriggers works)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=pd.read_csv('Data.csv').loc[:, [\"SR Summary\"]][\"SR Summary\"];\n",
    "file[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inspection dielectric leak at digger fitting in cab remove extension shaft from winch emg stop not working at controls boom cuts out wait or play with outriggers works'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean=[re.sub(r\"  +\",\" \",re.sub(r\"(?![\\w\\s]).\", \" \", line)).lower().strip() for line in file] #remove non-alphaneumeric\n",
    "clean[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tokens, Bigrams, Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_summary=\" \".join([line for line in clean])\n",
    "tokens = nltk.word_tokenize(appended_summary)\n",
    "freq = nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('service', 158),\n",
       " ('request', 155),\n",
       " ('inspection', 73),\n",
       " ('pm', 50),\n",
       " ('dielectric', 35),\n",
       " ('annual', 29),\n",
       " ('and', 29),\n",
       " ('road', 27),\n",
       " ('boom', 24),\n",
       " ('leak', 22)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('service', 'request'), 155),\n",
       " (('road', 'service'), 27),\n",
       " (('inspection', 'pm'), 27),\n",
       " (('and', 'dielectric'), 19),\n",
       " (('pm', 'and'), 17),\n",
       " (('annual', 'inspection'), 15),\n",
       " (('repairs', 'from'), 14),\n",
       " (('annual', 'pm'), 13),\n",
       " (('from', 'inspection'), 13),\n",
       " (('dielectric', 'test'), 12)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = [bigram for line in clean for bigram in list(nltk.bigrams(line.split(\" \")))]\n",
    "bigram_freq = nltk.FreqDist(list(bigrams))\n",
    "sorted_bigram_freq = bigram_freq.most_common()\n",
    "sorted_bigram_freq[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('road', 'service', 'request'), 26),\n",
       " (('pm', 'and', 'dielectric'), 17),\n",
       " (('repairs', 'from', 'inspection'), 13),\n",
       " (('inspection', 'pm', 'and'), 12),\n",
       " (('annual', 'inspection', 'ndt'), 6),\n",
       " (('and', 'dielectric', 'test'), 6),\n",
       " (('inspection', 'pm', 'dielectric'), 6),\n",
       " (('receive', 'prep', 'unit'), 5),\n",
       " (('annual', 'pm', 'and'), 5),\n",
       " (('inspection', '6', 'month'), 5)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = [trigram for line in clean for trigram in list(nltk.trigrams(line.split(\" \")))]\n",
    "trigram_freq = nltk.FreqDist(list(trigrams))\n",
    "sorted_trigram_freq = trigram_freq.most_common()\n",
    "sorted_trigram_freq[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def verb_checker(pair):\n",
    "    if pair[1].startswith(\"V\"):\n",
    "        \n",
    "        return Word(pair[0]).lemmatize(\"v\")\n",
    "    else:\n",
    "        return pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complete', 'foot', 'pedal', 'wire', 'inspection']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "new_tokens = [verb_checker(item) for item in tagged] \n",
    "new_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens_tagged = nltk.pos_tag(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_of_pos = {\"VB\":[], \"JJ\":[], \"RB\":[], \"NN\":[]}\n",
    "for token in set(new_tokens):\n",
    "    pair = nltk.pos_tag([token])[0]\n",
    "    if pair[1].startswith(\"VB\"):\n",
    "        dic_of_pos[\"VB\"].append(pair[0])\n",
    "    if pair[1].startswith(\"JJ\"):\n",
    "        dic_of_pos[\"JJ\"].append(pair[0])\n",
    "    if pair[1].startswith(\"NN\"):\n",
    "        dic_of_pos[\"NN\"].append(pair[0])\n",
    "    if pair[1].startswith(\"RB\"):\n",
    "        dic_of_pos[\"RB\"].append(pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('service', 158),\n",
       " ('request', 155),\n",
       " ('inspection', 73),\n",
       " ('pm', 50),\n",
       " ('dielectric', 35),\n",
       " ('leak', 30),\n",
       " ('annual', 29),\n",
       " ('and', 29),\n",
       " ('road', 27),\n",
       " ('boom', 24)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens_freq = nltk.FreqDist(new_tokens)\n",
    "new_tokens_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequent Nouns/Verbs/Adjectives/Adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('service', 158),\n",
       " ('request', 155),\n",
       " ('inspection', 73),\n",
       " ('pm', 50),\n",
       " ('dielectric', 35),\n",
       " ('road', 27),\n",
       " ('boom', 24),\n",
       " ('leak', 22),\n",
       " ('repairs', 17),\n",
       " ('test', 16)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = dic_of_pos[\"NN\"]\n",
    "noun_freq = [(item, freq[item]) for item in nouns]\n",
    "sorted_noun_freq = sorted(noun_freq, key = lambda x: x[1], reverse = True)\n",
    "sorted_noun_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 17),\n",
       " ('replace', 11),\n",
       " ('see', 2),\n",
       " ('slow', 2),\n",
       " ('do', 2),\n",
       " ('cracked', 1),\n",
       " ('resealed', 1),\n",
       " ('come', 1),\n",
       " ('leaking', 1),\n",
       " ('remove', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = dic_of_pos[\"VB\"]\n",
    "verb_freq = [(item, new_tokens_freq[item]) for item in verbs]\n",
    "sorted_verb_freq = sorted(verb_freq, key = lambda x: x[1], reverse = True)\n",
    "sorted_verb_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('annual', 29),\n",
       " ('upper', 9),\n",
       " ('inoperable', 4),\n",
       " ('lower', 3),\n",
       " ('new', 2),\n",
       " ('complete', 2),\n",
       " ('loose', 2),\n",
       " ('visual', 2),\n",
       " ('severe', 1),\n",
       " ('own', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = dic_of_pos[\"JJ\"]\n",
    "adj_freq = [(item, freq[item]) for item in adj ]\n",
    "sorted_adj_freq= sorted(adj_freq, key = lambda x:x[1], reverse = True)\n",
    "sorted_adj_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 11),\n",
       " ('down', 4),\n",
       " ('up', 3),\n",
       " ('close', 1),\n",
       " ('apart', 1),\n",
       " ('belly', 1),\n",
       " ('intermittently', 1),\n",
       " ('there', 1),\n",
       " ('correctly', 1),\n",
       " ('back', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adverbs = dic_of_pos[\"RB\"]\n",
    "adverb_freq = [(item, freq[item]) for item in adverbs]\n",
    "sorted_adverb_freq = sorted(adverb_freq, key = lambda x: x[1], reverse = True)\n",
    "sorted_adverb_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('annual', 'inspection', 'ndt'),\n",
       " 'apart',\n",
       " ('road', 'service', 'request'),\n",
       " 'inoperable',\n",
       " 'lower']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_provider(parameter_vector):\n",
    "    feature_pool=[sorted_noun_freq, sorted_verb_freq, sorted_adj_freq, sorted_adverb_freq, sorted_bigram_freq, sorted_trigram_freq]\n",
    "    features=[]\n",
    "    for i in range(len(parameter_vector)):\n",
    "        features+=[feature[0] for feature in feature_pool[i][0:parameter_vector[i]]]\n",
    "    return list(set(features))\n",
    "\n",
    "features_used = feature_provider([5,5,5,5,5,5])\n",
    "features_used[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
